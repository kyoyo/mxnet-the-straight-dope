{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax函数\n",
    "\n",
    "[详细说明](https://zhuanlan.zhihu.com/p/25723112)\n",
    "\n",
    "$\\Large{S_i = \\frac{e^i}{\\sum_{j}e^j} }$\n",
    "\n",
    "i 表示第i个元素， i = 1....j\n",
    "\n",
    "它将多个神经元的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类！\n",
    "\n",
    "二元分类就是只有一个概率为1，其它概率都是0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉熵损失函数\n",
    "\n",
    "\n",
    "$\\Large{Loss = -\\sum_{i}y_ilna_i}$\n",
    "\n",
    "其中y代表我们的真实值，a代表我们softmax求出的值。i代表的是输出结点的标号\n",
    "\n",
    "其中$y_i = 1 $,那么形式变为$Loss = -lna_i$\n",
    "\n",
    "<img src=\"img/softmax1.jpg\" width=\"300px\" height=\"300px\" />\n",
    "\n",
    "z4 = w41*o1+w42*o2+w43*o3\n",
    "\n",
    "z5 = w51*o1+w52*o2+w53*o3\n",
    "\n",
    "z6 = w61*o1+w62*o2+w63*o3\n",
    "\n",
    "z4,z5,z6分别代表结点4,5,6的输出，01,02,03代表是结点1,2,3往后传的输入.\n",
    "\n",
    "求导分析如下：\n",
    "\n",
    "参数的形式在该例子中，总共分为w41,w42,w43,w51,w52,w53,w61,w62,w63.这些，那么比如我要求出w41,w42,w43的偏导，就需要将Loss函数求偏导传到结点4，然后再利用链式法则继续求导即可，举个例子此时求w41的偏导为:\n",
    "\n",
    "\n",
    "$ \\Large{\\frac {\\partial Loss}{\\partial w41} \n",
    "= \\frac {\\partial Loss}{\\partial a4} \\cdot \\frac {\\partial a4}{\\partial z4} \\cdot \\frac {\\partial z4}{\\partial w41} } \n",
    "= -\\frac{1}{a4} \\cdot  \\frac {\\partial a4}{\\partial z4} \\cdot o1\n",
    "$\n",
    "\n",
    "关键求出 $ \\Large{\\frac {\\partial a4}{\\partial z4}} $\n",
    "\n",
    "w51.....w63等参数的偏导同理可以求出，那么我们的关键就在于Loss函数对于结点4,5,6的偏导怎么求，如下：\n",
    "\n",
    "这里分为俩种情况："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if j = i\n",
    "\n",
    " $\\Large{ \n",
    " \\frac {\\partial a_j}{\\partial z_i} \n",
    " = \\frac {\\partial \\frac{e^{z_j}}{\\sum_{k}e^{z_k}} }{\\partial z_i}  \n",
    " = \\frac {(e^{z_j})' \\cdot \\sum_{k}e^{z_k} - e^{z_j} \\cdot e^{z_j} }{(\\sum_{k}e^{z_k})^2}\n",
    " =  \\frac{e^{z_j}}{\\sum_{k}e^{z_k}} -  \\frac{e^{z_j}}{\\sum_{k}e^{z_k}} \\cdot  \\frac{e^{z_j}}{\\sum_{k}e^{z_k}}\n",
    " = a_j (1- a_j)\n",
    " }$\n",
    " \n",
    "  $e^{z_i} $第i个的概率为1，由于 j = i ,  $e^{z_i} = e^{z_j} $\n",
    "  \n",
    "  \n",
    " $ \\Large{\\frac {\\partial Loss}{\\partial w_{i}} \n",
    "= -\\frac{1}{a_{j}} \\cdot  a_j (1- a_j) \\cdot o_{i}\n",
    "= (a_j - 1) \\cdot o_{i}\n",
    "}$\n",
    "\n",
    " if $ j \\neq i$\n",
    " \n",
    "  $\\Large{ \n",
    " \\frac {\\partial a_j}{\\partial z_i} \n",
    " = \\frac {\\partial \\frac{e^{z_j}}{\\sum_{k}e^{z_k}} }{\\partial z_i}  \n",
    " = \\frac {0 \\cdot \\sum_{k}e^{z_k} - e^{z_i} \\cdot e^{z_j} }{(\\sum_{k}e^{z_k})^2}\n",
    " =   -  \\frac{e^{z_i}}{\\sum_{k}e^{z_k}} \\cdot  \\frac{e^{z_j}}{\\sum_{k}e^{z_k}}\n",
    " = -a_j a_i \n",
    " }$\n",
    " \n",
    " $e^{z_j} 为常数，所以(e^{z_j})' = 0 $\n",
    " \n",
    " \n",
    "  $ \\Large{\\frac {\\partial Loss}{\\partial w_{i}} \n",
    "= -\\frac{1}{a_{j}} \\cdot  -a_j a_i \\cdot o_{i}\n",
    "= a_i \\cdot o_{i}\n",
    "}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
